{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:34:48.276419Z",
     "start_time": "2025-03-27T12:34:46.511761Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import wn\n",
    "\n",
    "from OMWMetricsExtractor import OMWMetricsExtractor\n",
    "\n",
    "from utils import get_path_from_root, get_resource_word_match\n",
    "from analyzer import OMWBasicnessAnalyzer\n",
    "from utils_plot import plot_heatmap, plot_spaghettiplot, plot_clustermap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6768cd22c9b67f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:34:48.282878Z",
     "start_time": "2025-03-27T12:34:48.280090Z"
    }
   },
   "outputs": [],
   "source": [
    "enable_plots = False\n",
    "use_ili_list = False\n",
    "langs = (\"en\", \"it\", \"nb\", \"es\")\n",
    "# Choose resource set type: \"mixed\" (mixed random words), \"important\" (important words), \"selected\" (selected ilis/synsets), \"culture\" (all culture words)\n",
    "resource_set_type = \"annotation_culture_gold_it\"\n",
    "fixed_thresholds = [0.25, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71f2ae7d41d77d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:34:48.378557Z",
     "start_time": "2025-03-27T12:34:48.373310Z"
    }
   },
   "outputs": [],
   "source": [
    "if resource_set_type == \"mixed\":\n",
    "    out_prefix = \"mixed_words\"\n",
    "    input_path = get_path_from_root(f\"resources/{out_prefix}_omw.csv\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "elif resource_set_type == \"important\":\n",
    "    out_prefix = \"important_words\"\n",
    "    input_path = get_path_from_root(f\"resources/{out_prefix}_omw.csv\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "elif resource_set_type == \"selected\":\n",
    "    out_prefix = \"selected_ilis\"\n",
    "    selected_ilis_path = get_path_from_root(\"resources/selected_ilis_omw.csv\")\n",
    "    selected_words_path = get_path_from_root(\"resources/selected_words_omw.csv\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "    synset_word_match_dict = get_resource_word_match(selected_ilis_path, selected_words_path)\n",
    "elif resource_set_type == \"culture\":\n",
    "    out_prefix = \"all_culture\"\n",
    "    input_path = get_path_from_root(f\"resources/culture/{out_prefix}.csv\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "elif resource_set_type == \"selected_culture\":\n",
    "    out_prefix = \"selected_culture\"\n",
    "    input_path = get_path_from_root(\"resources/culture/ili_es_culture_filtered.csv\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "elif resource_set_type == \"annotation_culture\":\n",
    "    out_prefix = \"annotation_culture_copy\"\n",
    "    input_path = get_path_from_root(\"resources/annotation/culture_annotated_silver_simple_majority_voting.xlsx\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "elif resource_set_type == \"annotation_culture_gold_it\":\n",
    "    out_prefix = \"annotation_culture_gold_it_copy\"\n",
    "    input_path = get_path_from_root(\"resources/annotation/culture_annotated_gold_it_majority_voting.xlsx\")\n",
    "    json_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.json\")\n",
    "    csv_path = get_path_from_root(f\"results/omw/{out_prefix}_omw_extracted.csv\")\n",
    "    analysis_name = f\"{out_prefix}_omw_scored\"\n",
    "else:\n",
    "    raise ValueError(f\"Invalid resource_set_type: {resource_set_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f889d42202b3f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:34:48.510587Z",
     "start_time": "2025-03-27T12:34:48.416649Z"
    }
   },
   "outputs": [],
   "source": [
    "if resource_set_type == \"selected\":\n",
    "    # Load selected ilis\n",
    "    df = pd.read_csv(selected_ilis_path)\n",
    "    all_synsets = []\n",
    "    \n",
    "    # Extract synsets matching the selected ilis\n",
    "    for column in df.columns:\n",
    "        for ili_id in df[column]:\n",
    "            word = synset_word_match_dict[column][ili_id]\n",
    "            print(f\"ILI id: {ili_id}, Word: {word}\")\n",
    "            en_synsets = wn.synsets(ili=ili_id, lang=\"en\")\n",
    "            all_synsets.extend(en_synsets)\n",
    "    # print()\n",
    "    # print(f\"Number of selected ilis: {df.shape[0]}\")\n",
    "    # print(f\"Number of extracted synsets: {len(all_synsets)}\")\n",
    "    input = all_synsets\n",
    "elif resource_set_type == \"selected_culture\":\n",
    "    # Load selected culture words\n",
    "    df = pd.read_csv(input_path)\n",
    "    df[\"ilis\"] = df[\"ilis\"].apply(ast.literal_eval)\n",
    "    input = df\n",
    "elif resource_set_type in [\"annotation_culture\", \"annotation_culture_gold_it\"]:\n",
    "    # Load annotation culture ilis\n",
    "    df = pd.read_excel(input_path)\n",
    "    input = df[\"ili\"].tolist()\n",
    "    use_ili_list = True\n",
    "else:\n",
    "    # Load resources from csv\n",
    "    df = pd.read_csv(input_path)\n",
    "    words = df[\"col1\"].tolist()\n",
    "    input = words\n",
    "    # print(f\"Used words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d015e66566fd031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:34:48.523809Z",
     "start_time": "2025-03-27T12:34:48.519553Z"
    }
   },
   "outputs": [],
   "source": [
    "extractor = OMWMetricsExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d54db78ebc46d7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:35:43.851505Z",
     "start_time": "2025-03-27T12:34:48.569395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evilscript/.local/share/Cryptomator/mnt/Sync/Projects/SilverTesting/src/classification/OMWMetricsExtractor.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gloss'].replace({'nd'}, None, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Extract synsets data\n",
    "data_dict = extractor.extract(input, verbose=False, json_path=json_path, csv_path=csv_path, \n",
    "                              filter_zero_freq=True, languages=langs, max_lemmas=3, use_ili_list=use_ili_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3439a14ac6d42e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:35:43.921861Z",
     "start_time": "2025-03-27T12:35:43.906388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Synset</th>\n",
       "      <th>ili</th>\n",
       "      <th>Gloss</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>n_hyponyms</th>\n",
       "      <th>n_synonyms</th>\n",
       "      <th>n_syn_senses</th>\n",
       "      <th>word_length</th>\n",
       "      <th>word_frequency</th>\n",
       "      <th>pronounce_complexity</th>\n",
       "      <th>word_in_children_res</th>\n",
       "      <th>word_in_second_lang_learn_res</th>\n",
       "      <th>n_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Synset('omw-en-15168185-n')</td>\n",
       "      <td>i116927</td>\n",
       "      <td>12 o'clock at night; the middle of the night</td>\n",
       "      <td>midnight</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Synset('omw-en-07929519-n')</td>\n",
       "      <td>i78981</td>\n",
       "      <td>a beverage consisting of an infusion of ground...</td>\n",
       "      <td>java</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>Synset('omw-en-07929519-n')</td>\n",
       "      <td>i78981</td>\n",
       "      <td>a beverage consisting of an infusion of ground...</td>\n",
       "      <td>coffee</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Synset('omw-en-07933274-n')</td>\n",
       "      <td>i79004</td>\n",
       "      <td>a beverage made by steeping tea leaves in water</td>\n",
       "      <td>tea</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Synset('omw-en-09328904-n')</td>\n",
       "      <td>i85647</td>\n",
       "      <td>a body of (usually fresh) water surrounded by ...</td>\n",
       "      <td>lake</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>es</td>\n",
       "      <td>Synset('omw-es-03743902-n')</td>\n",
       "      <td>i56131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>monumento</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>es</td>\n",
       "      <td>Synset('omw-es-10547145-n')</td>\n",
       "      <td>i92688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>santo</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>es</td>\n",
       "      <td>Synset('omw-es-02395406-n')</td>\n",
       "      <td>i48199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sus</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>es</td>\n",
       "      <td>Synset('omw-es-02395406-n')</td>\n",
       "      <td>i48199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cerdo</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>es</td>\n",
       "      <td>Synset('omw-es-02395406-n')</td>\n",
       "      <td>i48199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>puerco</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>467 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language                       Synset      ili  \\\n",
       "0         en  Synset('omw-en-15168185-n')  i116927   \n",
       "1         en  Synset('omw-en-07929519-n')   i78981   \n",
       "2         en  Synset('omw-en-07929519-n')   i78981   \n",
       "3         en  Synset('omw-en-07933274-n')   i79004   \n",
       "4         en  Synset('omw-en-09328904-n')   i85647   \n",
       "..       ...                          ...      ...   \n",
       "462       es  Synset('omw-es-03743902-n')   i56131   \n",
       "463       es  Synset('omw-es-10547145-n')   i92688   \n",
       "464       es  Synset('omw-es-02395406-n')   i48199   \n",
       "465       es  Synset('omw-es-02395406-n')   i48199   \n",
       "466       es  Synset('omw-es-02395406-n')   i48199   \n",
       "\n",
       "                                                 Gloss      Lemma  n_hyponyms  \\\n",
       "0         12 o'clock at night; the middle of the night   midnight           0   \n",
       "1    a beverage consisting of an infusion of ground...       java          13   \n",
       "2    a beverage consisting of an infusion of ground...     coffee          13   \n",
       "3      a beverage made by steeping tea leaves in water        tea           5   \n",
       "4    a body of (usually fresh) water surrounded by ...       lake          51   \n",
       "..                                                 ...        ...         ...   \n",
       "462                                                NaN  monumento           8   \n",
       "463                                                NaN      santo          13   \n",
       "464                                                NaN        sus           1   \n",
       "465                                                NaN      cerdo           1   \n",
       "466                                                NaN     puerco           1   \n",
       "\n",
       "     n_synonyms  n_syn_senses  word_length  word_frequency  \\\n",
       "0             1             1            8        0.000020   \n",
       "1             2             7            4        0.000010   \n",
       "2             2             7            6        0.000072   \n",
       "3             1             5            3        0.000054   \n",
       "4             1             3            4        0.000068   \n",
       "..          ...           ...          ...             ...   \n",
       "462           1             3            9        0.000017   \n",
       "463           1             3            5        0.000074   \n",
       "464           5            10            3        0.002340   \n",
       "465           5            10            5        0.000013   \n",
       "466           5            10            6        0.000003   \n",
       "\n",
       "     pronounce_complexity  word_in_children_res  \\\n",
       "0                   0.638                     0   \n",
       "1                   0.820                     0   \n",
       "2                   0.344                     0   \n",
       "3                   0.193                     0   \n",
       "4                   0.193                     0   \n",
       "..                    ...                   ...   \n",
       "462                 0.206                     0   \n",
       "463                 0.201                     0   \n",
       "464                 0.188                     0   \n",
       "465                 0.192                     0   \n",
       "466                 0.778                     0   \n",
       "\n",
       "     word_in_second_lang_learn_res  n_senses  \n",
       "0                                0         1  \n",
       "1                                0         3  \n",
       "2                                1         4  \n",
       "3                                1         5  \n",
       "4                                0         3  \n",
       "..                             ...       ...  \n",
       "462                              1         3  \n",
       "463                              0         3  \n",
       "464                              0         2  \n",
       "465                              0         5  \n",
       "466                              1         1  \n",
       "\n",
       "[467 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load synsets data from csv\n",
    "all_synsets_df = pd.read_csv(csv_path)\n",
    "all_synsets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b600962351ba1f5",
   "metadata": {},
   "source": [
    "## Basicness Analysis: Calculation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b58af968e50a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:35:44.126509Z",
     "start_time": "2025-03-27T12:35:44.105100Z"
    }
   },
   "outputs": [],
   "source": [
    "# opt_path = get_path_from_root(\"resources/annotation/culture_annotated_silver_simple_majority_voting.xlsx\")\n",
    "opt_path = get_path_from_root(\"resources/annotation/culture_annotated_gold_it_majority_voting.xlsx\")\n",
    "analyzer = OMWBasicnessAnalyzer(all_synsets_df, opt_set_path=opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfabbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- en specific weights ---\n",
      "\tword_frequency_weight: 0.4975194119970945\n",
      "\tword_length_weight: -0.1648349442802383\n",
      "\tpronounce_complexity_weight: -0.13481534366354\n",
      "\tn_hyponyms_weight: 0.1610916023329112\n",
      "\tn_synonyms_weight: -0.2137141879710336\n",
      "\tn_senses_weight: -0.0732411059719357\n",
      "\tword_in_children_res_weight: 0.262514805918938\n",
      "\tword_in_second_lang_learn_res_weight: 0.3522947679483945\n",
      "\tn_syn_senses_weight: -0.2084357095723361\n",
      "\n",
      "--- it specific weights ---\n",
      "\tword_frequency_weight: 0.4303661205459141\n",
      "\tword_length_weight: -0.4199257170488138\n",
      "\tpronounce_complexity_weight: -0.1993844641840826\n",
      "\tn_hyponyms_weight: 0.350961698701289\n",
      "\tn_synonyms_weight: -0.1981350313136889\n",
      "\tn_senses_weight: 0.0872046033524559\n",
      "\tword_in_children_res_weight: 0.3212639278934397\n",
      "\tword_in_second_lang_learn_res_weight: 0.3983495968117755\n",
      "\tn_syn_senses_weight: -0.091663880259736\n",
      "\n",
      "--- es specific weights ---\n",
      "\tword_frequency_weight: 0.3948452796526028\n",
      "\tword_length_weight: -0.3960605202906034\n",
      "\tpronounce_complexity_weight: -0.2997551158457093\n",
      "\tn_hyponyms_weight: 0.3031001184515678\n",
      "\tn_synonyms_weight: -0.2255253849982728\n",
      "\tn_senses_weight: -0.0317824762272702\n",
      "\tword_in_children_res_weight: 0.2451801272754888\n",
      "\tword_in_second_lang_learn_res_weight: 0.1721046586314572\n",
      "\tn_syn_senses_weight: -0.1608121257028055\n",
      "\n",
      "--- nb specific weights ---\n",
      "\tword_frequency_weight: 0.6043639316883362\n",
      "\tword_length_weight: -0.4139374388061199\n",
      "\tpronounce_complexity_weight: -0.4463694473266615\n",
      "\tn_hyponyms_weight: 0.0793667946640337\n",
      "\tn_synonyms_weight: 0.0147992206551884\n",
      "\tn_senses_weight: 0.226316233000255\n",
      "\tword_in_children_res_weight: 0.2957445996117107\n",
      "\tword_in_second_lang_learn_res_weight: 0.522245167624948\n",
      "\tn_syn_senses_weight: 0.1718956596181416\n"
     ]
    }
   ],
   "source": [
    "# Load correlation-based weights\n",
    "correlation_path = get_path_from_root(\"../../results/correlation/unfiltered/spearman_correlations.csv\")\n",
    "language_specific_weights = OMWBasicnessAnalyzer.load_correlation_weights(correlation_path)\n",
    "\n",
    "# Set the language-specific weights\n",
    "analyzer.set_language_specific_weights(language_specific_weights)\n",
    "\n",
    "# Display the weights for each language\n",
    "for lang, weights in language_specific_weights.items():\n",
    "    print(f\"\\n--- {lang} specific weights ---\")\n",
    "    for key, value in weights.items():\n",
    "        print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87c7868f5255f581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:35:44.271990Z",
     "start_time": "2025-03-27T12:35:44.153661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>basicness_score_experimental</th>\n",
       "      <th>basicness_rank</th>\n",
       "      <th>basicness_score</th>\n",
       "      <th>word_in_children_res</th>\n",
       "      <th>word_in_second_lang_learn_res</th>\n",
       "      <th>en_lemmas</th>\n",
       "      <th>n_hyponyms</th>\n",
       "      <th>n_synonyms</th>\n",
       "      <th>n_syn_senses</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_n_senses</th>\n",
       "      <th>normalized_length</th>\n",
       "      <th>normalized_pronounce_complexity</th>\n",
       "      <th>normalized_n_senses</th>\n",
       "      <th>normalized_frequency</th>\n",
       "      <th>normalized_n_hyponyms</th>\n",
       "      <th>normalized_n_synonyms</th>\n",
       "      <th>example_en_lemma</th>\n",
       "      <th>example_en_gloss</th>\n",
       "      <th>ili</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>0.752695</td>\n",
       "      <td>4</td>\n",
       "      <td>0.178189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rose, rosebush</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>rose</td>\n",
       "      <td>any of many shrubs of the genus Rosa that bear...</td>\n",
       "      <td>i103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.728238</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rose, rosebush</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rose</td>\n",
       "      <td>any of many shrubs of the genus Rosa that bear...</td>\n",
       "      <td>i103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es</td>\n",
       "      <td>0.662313</td>\n",
       "      <td>3</td>\n",
       "      <td>0.202044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rose, rosebush</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>rose</td>\n",
       "      <td>any of many shrubs of the genus Rosa that bear...</td>\n",
       "      <td>i103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>0.656120</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rose, rosebush</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>rose</td>\n",
       "      <td>any of many shrubs of the genus Rosa that bear...</td>\n",
       "      <td>i103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.972162</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>wood</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wood</td>\n",
       "      <td>the hard fibrous lignified substance under the...</td>\n",
       "      <td>i116549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>it</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>snow, snowfall</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>snow</td>\n",
       "      <td>precipitation falling from clouds in the form ...</td>\n",
       "      <td>i98073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>it</td>\n",
       "      <td>0.984573</td>\n",
       "      <td>4</td>\n",
       "      <td>0.509686</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weather condition, conditions, weather</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>weather condition</td>\n",
       "      <td>the atmospheric conditions that comprise the s...</td>\n",
       "      <td>i98170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>es</td>\n",
       "      <td>0.966547</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>weather condition, conditions, weather</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.453217</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>weather condition</td>\n",
       "      <td>the atmospheric conditions that comprise the s...</td>\n",
       "      <td>i98170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>en</td>\n",
       "      <td>0.894981</td>\n",
       "      <td>4</td>\n",
       "      <td>0.236577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>weather condition, conditions, weather</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.145011</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>weather condition</td>\n",
       "      <td>the atmospheric conditions that comprise the s...</td>\n",
       "      <td>i98170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.794759</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weather condition, conditions, weather</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275951</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>weather condition</td>\n",
       "      <td>the atmospheric conditions that comprise the s...</td>\n",
       "      <td>i98170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language  basicness_score_experimental  basicness_rank  basicness_score  \\\n",
       "0         en                      0.752695               4         0.178189   \n",
       "1         nb                      0.728238               3         1.000000   \n",
       "2         es                      0.662313               3         0.202044   \n",
       "3         it                      0.656120               3         0.000000   \n",
       "4         nb                      0.972162               4         1.000000   \n",
       "..       ...                           ...             ...              ...   \n",
       "275       it                      0.656449               3         0.000000   \n",
       "276       it                      0.984573               4         0.509686   \n",
       "277       es                      0.966547               4         0.000000   \n",
       "278       en                      0.894981               4         0.236577   \n",
       "279       nb                      0.794759               4         1.000000   \n",
       "\n",
       "     word_in_children_res  word_in_second_lang_learn_res  \\\n",
       "0                       0                              0   \n",
       "1                       1                              1   \n",
       "2                       0                              0   \n",
       "3                       0                              0   \n",
       "4                       0                              0   \n",
       "..                    ...                            ...   \n",
       "275                     0                              0   \n",
       "276                     1                              1   \n",
       "277                     1                              0   \n",
       "278                     0                              1   \n",
       "279                     1                              1   \n",
       "\n",
       "                                  en_lemmas  n_hyponyms  n_synonyms  \\\n",
       "0                            rose, rosebush          11           2   \n",
       "1                            rose, rosebush           0           1   \n",
       "2                            rose, rosebush           0           1   \n",
       "3                            rose, rosebush           5           2   \n",
       "4                                      wood           0           1   \n",
       "..                                      ...         ...         ...   \n",
       "275                          snow, snowfall           2           2   \n",
       "276  weather condition, conditions, weather          13           1   \n",
       "277  weather condition, conditions, weather           6           4   \n",
       "278  weather condition, conditions, weather          11           4   \n",
       "279  weather condition, conditions, weather           2           1   \n",
       "\n",
       "     n_syn_senses  ...  avg_n_senses  normalized_length  \\\n",
       "0               4  ...      2.000000           0.300000   \n",
       "1               1  ...      1.000000           0.125000   \n",
       "2               5  ...      5.000000           0.166667   \n",
       "3              10  ...      5.000000           0.214286   \n",
       "4               2  ...      2.000000           0.000000   \n",
       "..            ...  ...           ...                ...   \n",
       "275             5  ...      2.500000           0.285714   \n",
       "276            17  ...     17.000000           0.214286   \n",
       "277             9  ...      2.666667           0.888889   \n",
       "278             6  ...      1.666667           0.833333   \n",
       "279             1  ...      1.000000           0.000000   \n",
       "\n",
       "     normalized_pronounce_complexity  normalized_n_senses  \\\n",
       "0                             0.4865             0.142857   \n",
       "1                             0.4660             0.000000   \n",
       "2                             0.1860             0.307692   \n",
       "3                             0.1925             0.225806   \n",
       "4                             0.4420             0.111111   \n",
       "..                               ...                  ...   \n",
       "275                           0.1995             0.064516   \n",
       "276                           0.5240             1.000000   \n",
       "277                           0.8110             0.128205   \n",
       "278                           0.6320             0.095238   \n",
       "279                           0.1860             0.000000   \n",
       "\n",
       "     normalized_frequency  normalized_n_hyponyms  normalized_n_synonyms  \\\n",
       "0                0.065887               0.055000               0.090909   \n",
       "1                0.031567               0.000000               0.000000   \n",
       "2                0.063394               0.000000               0.000000   \n",
       "3                0.033582               0.068493               0.090909   \n",
       "4                1.000000               0.000000               0.000000   \n",
       "..                    ...                    ...                    ...   \n",
       "275              0.014671               0.027397               0.090909   \n",
       "276              1.000000               0.178082               0.000000   \n",
       "277              0.453217               0.162162               0.750000   \n",
       "278              0.145011               0.055000               0.272727   \n",
       "279              0.275951               0.400000               0.000000   \n",
       "\n",
       "      example_en_lemma                                   example_en_gloss  \\\n",
       "0                 rose  any of many shrubs of the genus Rosa that bear...   \n",
       "1                 rose  any of many shrubs of the genus Rosa that bear...   \n",
       "2                 rose  any of many shrubs of the genus Rosa that bear...   \n",
       "3                 rose  any of many shrubs of the genus Rosa that bear...   \n",
       "4                 wood  the hard fibrous lignified substance under the...   \n",
       "..                 ...                                                ...   \n",
       "275               snow  precipitation falling from clouds in the form ...   \n",
       "276  weather condition  the atmospheric conditions that comprise the s...   \n",
       "277  weather condition  the atmospheric conditions that comprise the s...   \n",
       "278  weather condition  the atmospheric conditions that comprise the s...   \n",
       "279  weather condition  the atmospheric conditions that comprise the s...   \n",
       "\n",
       "         ili  \n",
       "0    i103203  \n",
       "1    i103203  \n",
       "2    i103203  \n",
       "3    i103203  \n",
       "4    i116549  \n",
       "..       ...  \n",
       "275   i98073  \n",
       "276   i98170  \n",
       "277   i98170  \n",
       "278   i98170  \n",
       "279   i98170  \n",
       "\n",
       "[280 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze synsets data using correlation-based weights\n",
    "all_synsets_lang_syn_df = analyzer.analyze_lang_syn_group(word=analysis_name + \"_correlation_weights\", thresholds=fixed_thresholds)\n",
    "# Reset indexes\n",
    "all_synsets_lang_syn_df = all_synsets_lang_syn_df.reset_index(drop=True)\n",
    "all_synsets_lang_syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b209870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare previous weights with correlation-based weights\n",
    "used_weights = {\n",
    "    'word_frequency_weight': 0.3,\n",
    "    'word_length_weight': 2.0,\n",
    "    'pronounce_complexity_weight': 0.3,\n",
    "    'n_hyponyms_weight': 0.0,\n",
    "    'n_synonyms_weight': 0.0,\n",
    "    'n_senses_weight': 0.0,\n",
    "    'word_in_children_res_weight': 0.5,\n",
    "    'word_in_second_lang_learn_res_weight': 0.6,\n",
    "    'n_syn_senses_weight': 0.0\n",
    "}\n",
    "\n",
    "analyzer.set_weights(used_weights)\n",
    "analyzer.set_language_specific_weights(None)  # Disable language-specific weights\n",
    "\n",
    "all_synsets_uniform_df = analyzer.analyze_lang_syn_group(word=analysis_name + \"_uniform_weights\", thresholds=fixed_thresholds)\n",
    "all_synsets_uniform_df = all_synsets_uniform_df.reset_index(drop=True)\n",
    "\n",
    "# Re-enable language-specific weights for further analysis\n",
    "analyzer.set_language_specific_weights(language_specific_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1c325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation with Uniform Weights ===\n",
      "Rank evaluation: 0.0\n",
      "Ordinal regression loss: 4.7375\n",
      "\n",
      "=== Evaluation with Correlation-Based Weights ===\n",
      "Rank evaluation: 0.0\n",
      "Ordinal regression loss: 4.7375\n"
     ]
    }
   ],
   "source": [
    "# Compare evaluation metrics between uniform and correlation-based weights\n",
    "print(\"=== Evaluation with Uniform Weights ===\")\n",
    "analyzer.set_language_specific_weights(None)  # Use uniform weights\n",
    "eval_rank_uniform = analyzer.evaluate_accordance(allow_margin_error=True)\n",
    "eval_ord_reg_loss_uniform = analyzer.evaluate_ordinal_regression_loss()\n",
    "print(f\"Rank evaluation: {eval_rank_uniform}\")\n",
    "print(f\"Ordinal regression loss: {eval_ord_reg_loss_uniform}\")\n",
    "\n",
    "print(\"\\n=== Evaluation with Correlation-Based Weights ===\")\n",
    "analyzer.set_language_specific_weights(language_specific_weights)  # Use correlation weights\n",
    "eval_rank_corr = analyzer.evaluate_accordance(allow_margin_error=True)\n",
    "eval_ord_reg_loss_corr = analyzer.evaluate_ordinal_regression_loss()\n",
    "print(f\"Rank evaluation: {eval_rank_corr}\")\n",
    "print(f\"Ordinal regression loss: {eval_ord_reg_loss_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f549d98819607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:03:58.155185Z",
     "start_time": "2025-03-27T12:03:57.102818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "threshold = 0.4# create the folder results/omw if it does not exist\n",
    "os.makedirs(get_path_from_root(\"results/omw\"), exist_ok=True)\n",
    "eval_binary = analyzer.evaluate_basicness_score_binary(threshold=threshold)\n",
    "print(f\"--- Binary evaluation ---\")\n",
    "print(f\"threshold: {threshold}\")\n",
    "print(f\"weights:\")\n",
    "for key, value in used_weights.items():\n",
    "    print(f\"\\t{key}: {value}\")\n",
    "print(eval_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e83a498da00130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:03:59.960655Z",
     "start_time": "2025-03-27T12:03:58.201182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "eval_ord_reg_loss_train = analyzer.evaluate_ordinal_regression_loss(opt_split=\"train\")\n",
    "eval_ord_reg_loss_test = analyzer.evaluate_ordinal_regression_loss(opt_split=\"test\")\n",
    "eval_ord_reg_loss_full = analyzer.evaluate_ordinal_regression_loss()\n",
    "print(f\"Ordinal regression loss train: {eval_ord_reg_loss_train}\")\n",
    "print(f\"Ordinal regression loss test: {eval_ord_reg_loss_test}\")\n",
    "print(f\"Ordinal regression loss full: {eval_ord_reg_loss_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260447c27d77ca99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:03:59.978306Z",
     "start_time": "2025-03-27T12:03:59.976042Z"
    }
   },
   "outputs": [],
   "source": [
    "# accordance_overall = analyzer.get_overall_accordance()\n",
    "# accordance_test = analyzer.get_overall_accordance(opt_split=\"test\")\n",
    "# print(f\"Overall accordance: {accordance_overall}\")\n",
    "# print(f\"Test set overall accordance: {accordance_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedfb617b7ab175f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:04:01.634438Z",
     "start_time": "2025-03-27T12:04:00.027374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "eval_cum_ord_loss_train = analyzer.evaluate_cumulative_ordinal_loss(opt_split=\"train\")\n",
    "eval_cum_ord_loss_test = analyzer.evaluate_cumulative_ordinal_loss(opt_split=\"test\")\n",
    "eval_cum_ord_loss_full = analyzer.evaluate_cumulative_ordinal_loss()\n",
    "print(f\"Ordinal cumulative loss train: {eval_cum_ord_loss_train}\")\n",
    "print(f\"Ordinal cumulative loss test: {eval_cum_ord_loss_test}\")\n",
    "print(f\"Ordinal cumulative loss full: {eval_cum_ord_loss_full}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc421d51372950a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T12:04:03.237166Z",
     "start_time": "2025-03-27T12:04:01.657879Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_rank_train = analyzer.evaluate_accordance(opt_split=\"train\")\n",
    "eval_rank_test = analyzer.evaluate_accordance(opt_split=\"test\")\n",
    "eval_rank_full = analyzer.evaluate_accordance(allow_margin_error=True)\n",
    "print(f\"Rank train eval: {eval_rank_train}\")\n",
    "print(f\"Rank test eval: {eval_rank_test}\")\n",
    "print(f\"Rank full eval: {eval_rank_full}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd1c2d2352c0e4",
   "metadata": {},
   "source": [
    "## Basicness Analysis: Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135634fe8f7a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights, best_df = analyzer.optimize_weights_diff_evo(\"optimal\", \"rank\", optimize_thresholds=False, optimize_gamma=False, thresholds=fixed_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fcb369a932c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af745b6771eaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92365c30abb0c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_max_post_opt = analyzer.evaluate_basicness_score_max()\n",
    "print(f\"MAX eval post opt: {eval_max_post_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cacfdbc876d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mse_post_opt_train = analyzer.evaluate_basicness_score_mse()\n",
    "eval_mse_post_opt_test = analyzer.evaluate_basicness_score_mse(use_test_set=True)\n",
    "print(f\"MSE train eval post opt: {eval_mse_post_opt_train}\")\n",
    "print(f\"MSE test eval post opt: {eval_mse_post_opt_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162e033cb6677b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rank_post_opt_train = analyzer.evaluate_accordance(thresholds=fixed_thresholds)\n",
    "eval_rank_post_opt_test = analyzer.evaluate_accordance(use_test_set=True, thresholds=fixed_thresholds)\n",
    "print(f\"Rank train eval post opt: {eval_rank_post_opt_train}\")\n",
    "print(f\"Rank test eval post opt: {eval_rank_post_opt_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436816a00d55c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ord_reg_loss_train = analyzer.evaluate_ordinal_regression_loss()\n",
    "eval_ord_reg_loss_test = analyzer.evaluate_ordinal_regression_loss(use_test_set=True)\n",
    "print(f\"Ordinal regression loss train: {eval_ord_reg_loss_train}\")\n",
    "print(f\"Ordinal regression loss test: {eval_ord_reg_loss_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddcc4fd48ccdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = best_weights['gamma']\n",
    "eval_cum_ord_loss_train = analyzer.evaluate_cumulative_ordinal_loss(gamma=gamma)\n",
    "eval_cum_ord_loss_test = analyzer.evaluate_cumulative_ordinal_loss(opt_split=True, gamma=gamma)\n",
    "print(f\"Ordinal cumulative loss train: {eval_cum_ord_loss_train}\")\n",
    "print(f\"Ordinal cumulative loss test: {eval_cum_ord_loss_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5edb4673f49815",
   "metadata": {},
   "outputs": [],
   "source": [
    "accordance_overall = analyzer.get_overall_accordance(thresholds=fixed_thresholds)\n",
    "accordance_test = analyzer.get_overall_accordance(use_test_set=True, thresholds=fixed_thresholds)\n",
    "print(f\"Overall accordance: {accordance_overall}\")\n",
    "print(f\"Test set overall accordance: {accordance_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb0ebabbf5f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef031dd9d08fc5c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f23c2c9b8501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_plots:\n",
    "    plot_heatmap(all_synsets_lang_syn_df, limit=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007db1163fc82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_plots:\n",
    "    plot_spaghettiplot(all_synsets_lang_syn_df, limit=15, show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b7364b1bce8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_plots:\n",
    "    # Add rank column to dataframe\n",
    "    ranked_lang_syn_df = analyzer.add_basicness_rank(all_synsets_lang_syn_df)\n",
    "    ranked_lang_syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5848d98251e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_plots:\n",
    "    plot_clustermap(ranked_lang_syn_df, use_rank=True, limit=130)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
